---
title: "Stat. 652 Homework02a"
author: "Elaine Cao"
date: "`r format(Sys.time(), '%B %d, %Y')`"
format: 
  html:
    self-contained: true
---

- **Read:** 
       - [mdsr2e](https://mdsr-book.github.io/mdsr2e/) [Chapter 10](https://mdsr-book.github.io/mdsr2e/ch-modeling.html)
       - [mdsr2e](https://mdsr-book.github.io/mdsr2e/) [Chapter 11](https://mdsr-book.github.io/mdsr2e/ch-learningI.html)
       - Machine Learning with R, Second Edition, Chapter 3, 5, second half of Chapter 6.  To access the book [CSUEB Library Databases A-Z](https://library.csueastbay.edu/az.php?a=s) > Safari Books Online, register and access the book
- **Problems:**
       - 10.6 Exercises: Problem 3
       - 11.7 Exercises: Problem 6a, Run Models 1. Null Model, 2. Logistic Regression, 6. kNN, using training and test datasets, as described in part c of the problem.

Hint: For Problems 6a and 6b, explore the dataset before attempting to fit the models.  You will need to deal with the missing values before applying some or all of the models.  Which models do not work with missing data?

**Instructions:** Answer all questions in the space below the # headers.


# 10.6 Exercises: Problem 3

Investigators in the HELP (Health Evaluation and Linkage to Primary Care) study were interested in modeling the probability of being homeless (one or more nights spent on the street or in a shelter in the past six months vs. housed) as a function of age.

a) Generate a confusion matrix for the null model and interpret the result.
b) Fit and interpret logistic regression model for the probability of being homeless as a function of age.
c) What is the predicted probability of being homeless for a 20 year old? For a 40 year old?
d) Generate a confusion matrix for the second model and interpret the result.

### **Answer:**

Summarize your answer to the question here.  All code and comments should be below and your written answer above.

### **Code and Comments:**

```{r}
# load required packages
library(tidymodels)
library(yardstick)
library(mosaicData)

# Load the data
data(HELPrct)

# View the first 6 rows
head(HELPrct)

# Construct Null model
mod_null <- logistic_reg(mode = "classification") |>
  set_engine("glm") |>
  fit(homeless ~ 1, data = HELPrct, family = binomial)
pred <- select(HELPrct, homeless, age) |>
  bind_cols(predict(mod_null, new_data = HELPrct, type = "class")) |>
  rename(homeless_null = .pred_class)
pred
accuracy(pred, homeless, homeless_null)

# (a) Construct Confusion Matrix
confusionmatrix_null <- pred |>
  conf_mat(truth = homeless, estimate = homeless_null)
confusionmatrix_null

# (b) Fit the Logistic Regression Model
log_mod <- logistic_reg(mode = "classification") |>
  set_engine("glm") |>
  fit(homeless ~ age, data = HELPrct)
log_mod
# intercept = 0.95724, age coefficient = -0.02248
# Convert log numbers to probability
# p = 1 / (1 + exp(-log_number))
# Intercept:
1 / (1 + exp(-0.95724))
# Age coefficient:
1 / (1 + exp(0.02248))
# Interpretation: The probabiliy of being homeless when age = 0 is 72.26%. When the age increases, the probablity of being homeless decreases.

# (c) Predicted probablility of being homeless for age = 20 or 40.
log_20 <- 0.95724 - 0.02248 * 20
pred_age20 <- 1 / (1 + exp(-log_20))
pred_age20

log_40 <- 0.95724 - 0.02248 * 40
pred_age40 <- 1 / (1 + exp(-log_40))
pred_age40

# (d) Confusion matrix for (b) and interpret
pred_log <- select(HELPrct, homeless, age) |>
  bind_cols(predict(log_mod, new_data = HELPrct, type = "class")) |>
  rename(homeless_log = .pred_class)
confusionmatrix_log <- pred_log |>
  conf_mat(truth = homeless, estimate = homeless_log)
confusionmatrix_log
# Interpretation: 48 homeless person are correctly predicted; 35 housed person are wrongly predicted as homeless. 161 homeless person are wrongly predicted as housed person, while 209 housed persons are correctly predicted. 
```

# 11.7 Exercises: Problem 4

### **Answer:**

A decision tree does a good job on classifying storm types based on wind and pressure because it displays a clear picture on how to classify different storms; it considers many possible splits by selecting the important variables; it prunes the splits to improve the model. 

### **Code and Comments:**

```{r}
# scatterplot between the wind speed and pressure of these storms 
library(mdsr)
library(nasaweather)
library(rpart)
ggplot(data = storms, aes(x = pressure, y = wind, color = type)) +
  geom_point(alpha = 0.5)

# Remove rows with missing values
storms_new <- storms |> na.omit() |> mutate(type = as.factor(type))

# Check the first 6 rows of cleaned data set: storms_new
head(storms_new)

# Build a classifier for the type.
form <- as.formula("type ~ wind + pressure")
storm_dtree <- decision_tree(mode = "classification") |>
  set_engine("rpart") |>
  fit(form, data = storms_new)
storm_dtree

# Display the decision tree itself
library(partykit)
plot(as.party(storm_dtree$fit))

# Visualize the classifier in the data space
storms_new <- storms_new |>
  mutate(hi_wind = wind >= 62.5, mid_wind = wind <32.5, 
         pressure_split = pressure >= 985.5) |>
  bind_cols(
  predict(storm_dtree, new_data = storms_new, type = "class")
) |>
  rename(type_Dtree = .pred_class)

ggplot(data = storms_new, aes(x = wind, y = pressure)) + 
  geom_count(
    aes(color = type_Dtree, shape = pressure_split),
    position = position_jitter(width = 0, height = 0.1),
    alpha = 0.5
  ) +
  facet_wrap(~ hi_wind) +
  geom_vline(xintercept = 62.5, color = "dodgerblue", lty = 2)

```

# 11.7 Exercises: Problem 6a

Run Models 1. Null Model, 2. Logistic Regression, 6. kNN, using training and test datasets, as described in part c of the problem.

The ability to get a good night’s sleep is correlated with many positive health outcomes. The NHANES data set contains a binary variable SleepTrouble that indicates whether each person has trouble sleeping.

For each of the following models:

- Build a classifier for SleepTrouble
- Report its effectiveness on the NHANES training data
- Make an appropriate visualization of the model
- Interpret the results. What have you learned about people’s sleeping habits?

You may use whatever variables you like, except for SleepHrsNight.

- Null model
- Logistic regression
- k-NN

First separate the NHANES data set uniformly at random into 75% training and 25% testing sets. 

# Model 1: Null Model

### **Answer:**

Summarize your answer to the question here.  All code and comments should be below and your written answer above.

### **Code and Comments:**

```{r}
# load packages and dataset
library(NHANES)
library(pacman)
library(dplyr)
head(NHANES)

# explore the missing values
skim(NHANES)

NHANES |> select(SleepTrouble) |> 
  group_by (SleepTrouble) |> 
  summarize(n = n()) 


# Remove rows where 'SleepTrouble' or 'Poverty' is NA
nhanes_new <- NHANES |>
  drop_na(SleepTrouble, Poverty)

# Split the data to train data and test data
set.seed(364)
n <- nrow(nhanes_new)
nhanes_part <- nhanes_new |> initial_split(prop = 0.75)

train <- nhanes_part |> training()
test <- nhanes_part |> testing()
list(train, test) |> map_int(nrow)

# Build Null model
nhanes_null <- logistic_reg(mode = "classification") |>
  set_engine("glm") |>
  fit(SleepTrouble ~1, data = train)
nhanes_null

```

# Model 2: Logistic Regression

### **Answer:**

Summarize your answer to the question here.  All code and comments should be below and your written answer above.

### **Code and Comments:**

```{r}
# Build Logistic Regression model
nhanes_logmod <- logistic_reg(mode = "classification") |>
  set_engine("glm") |>
  fit(SleepTrouble ~ Poverty, data = train)
nhanes_logmod

```

# Model 7: kNN

### **Answer:**

Summarize your answer to the question here.  All code and comments should be below and your written answer above.

### **Code and Comments:**

```{r}
# Build KNN
# Load package
library(kknn)

# Distance 
train_q <- train |> select(SleepTrouble, where(is.numeric))
head(train_q)
nhanes_modknn <- nearest_neighbor(neighbors = 5, mode = "classification") |>
  set_engine("kknn", scale = TRUE) |>
  fit(SleepTrouble ~ Poverty, data = train_q)
nhanes_modknn
```

